{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m artist_name \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m][:][\u001b[38;5;241m0\u001b[39m][f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnames\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_name\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[1;32m      7\u001b[0m song_title \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m][:][\u001b[38;5;241m0\u001b[39m][f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnames\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[0;32m----> 8\u001b[0m artist_id \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msongs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnames\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist_id\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[1;32m      9\u001b[0m song_id \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m][:][\u001b[38;5;241m0\u001b[39m][f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnames\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msong_id\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mdecode()\n\u001b[1;32m     10\u001b[0m release \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m][:][\u001b[38;5;241m0\u001b[39m][f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnames\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mdecode()\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/anaconda3/envs/SGI/lib/python3.8/site-packages/h5py/_hl/dataset.py:841\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    839\u001b[0m mspace \u001b[38;5;241m=\u001b[39m h5s\u001b[38;5;241m.\u001b[39mcreate_simple(selection\u001b[38;5;241m.\u001b[39mmshape)\n\u001b[1;32m    840\u001b[0m fspace \u001b[38;5;241m=\u001b[39m selection\u001b[38;5;241m.\u001b[39mid\n\u001b[0;32m--> 841\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdxpl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dxpl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[38;5;66;03m# Patch up the output for NumPy\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract relevant fields for a recommendation algorithm\n",
    "data_list = []\n",
    "with h5py.File('Data/msd_summary_file.h5', 'r') as f:\n",
    "    try:\n",
    "        # Metadata fields\n",
    "        artist_name = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('artist_name')].decode()\n",
    "        song_title = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('title')].decode()\n",
    "        artist_id = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('artist_id')].decode()\n",
    "        song_id = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('song_id')].decode()\n",
    "        release = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('release')].decode()\n",
    "        hotness = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('song_hotttnesss')]\n",
    "        # artist_terms = [term.decode() for term in f['metadata']['artist_terms'][:]]\n",
    "        # artist_terms_freq = [term for term in f['metadata']['artist_terms_freq'][:]]\n",
    "        # Analysis fields\n",
    "        # track_id = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('track_id')].decode()\n",
    "        # tempo = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('tempo')]\n",
    "        # loudness = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('loudness')]\n",
    "        # duration = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('duration')]\n",
    "        # danceability = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('danceability')]\n",
    "        # energy = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('energy')]\n",
    "        # key = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('key')]\n",
    "        # mode = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('mode')]\n",
    "        # year = f['musicbrainz']['songs'][:][0][f['musicbrainz']['songs'].dtype.names.index('year')]\n",
    "        \n",
    "        # print(f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('track_id')].decode())\n",
    "        data_list.append({\n",
    "                        'song_id': song_id,\n",
    "                        # 'track_id': track_id,\n",
    "                        'artist_id': artist_id,\n",
    "                        'song_title': song_title,\n",
    "                        'artist_name': artist_name,\n",
    "                        'release': release,\n",
    "                        # 'artist_terms': artist_terms,\n",
    "                        # 'artist_terms_freq': artist_terms_freq,\n",
    "                        # 'song_hotness': hotness,\n",
    "                        # 'tempo': tempo,\n",
    "                        # 'loudness': loudness,\n",
    "                        # 'duration': duration,\n",
    "                        # 'danceability': danceability,\n",
    "                        # 'energy': energy,\n",
    "                        # 'key': key,\n",
    "                        # 'mode': mode,\n",
    "                        # 'year': year\n",
    "                    })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid location identifier (invalid location identifier)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manalysis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m][:][\u001b[38;5;241m0\u001b[39m][f[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalysis\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msongs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mnames\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrack_id\u001b[39m\u001b[38;5;124m'\u001b[39m)]\u001b[38;5;241m.\u001b[39mdecode()\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/anaconda3/envs/SGI/lib/python3.8/site-packages/h5py/_hl/group.py:357\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 357\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    360\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5o.pyx:241\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid location identifier (invalid location identifier)"
     ]
    }
   ],
   "source": [
    "f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('track_id')].decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"Data/MillionSongSubset/A/A/A/TRAAAAW128F429D538.h5\"\n",
    "\n",
    "# def print_dataset(name, obj):\n",
    "#     \"\"\"Helper function to print dataset values if the object is a dataset.\"\"\"\n",
    "#     if isinstance(obj, h5py.Dataset):\n",
    "#         print(f\"Dataset '{name}':\")\n",
    "#         print(obj[()])  # Print all values in the dataset as a NumPy array\n",
    "#     elif isinstance(obj, h5py.Group):\n",
    "#         print(f\"Group '{name}' contains:\")\n",
    "#         for key in obj.keys():\n",
    "#             print(f\"  - {key}\")\n",
    "\n",
    "# try:\n",
    "#     with h5py.File(filename, \"r\") as f:\n",
    "#         print(\"Keys at the root level:\", list(f.keys()))\n",
    "\n",
    "#         # Iterate over all items in the file and print data\n",
    "#         f.visititems(print_dataset)\n",
    "# except FileNotFoundError:\n",
    "#     print(f\"File '{filename}' not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"Data/MillionSongSubset\"\n",
    "\n",
    "data_list = []\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".h5\"):\n",
    "            file_path = os.path.join(root, file)\n",
    "            \n",
    "            # Extract relevant fields for a recommendation algorithm\n",
    "            with h5py.File(file_path, 'r') as f:\n",
    "                try:\n",
    "                    # Metadata fields\n",
    "                    artist_name = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('artist_name')].decode()\n",
    "                    song_title = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('title')].decode()\n",
    "                    artist_id = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('artist_id')].decode()\n",
    "                    song_id = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('song_id')].decode()\n",
    "                    release = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('release')].decode()\n",
    "                    hotness = f['metadata']['songs'][:][0][f['metadata']['songs'].dtype.names.index('song_hotttnesss')]\n",
    "                    artist_terms = [term.decode() for term in f['metadata']['artist_terms'][:]]\n",
    "                    artist_terms_freq = [term for term in f['metadata']['artist_terms_freq'][:]]\n",
    "                    \n",
    "                    # Analysis fields\n",
    "                    track_id = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('track_id')].decode()\n",
    "                    tempo = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('tempo')]\n",
    "                    loudness = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('loudness')]\n",
    "                    duration = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('duration')]\n",
    "                    danceability = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('danceability')]\n",
    "                    energy = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('energy')]\n",
    "                    key = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('key')]\n",
    "                    mode = f['analysis']['songs'][:][0][f['analysis']['songs'].dtype.names.index('mode')]\n",
    "                    year = f['musicbrainz']['songs'][:][0][f['musicbrainz']['songs'].dtype.names.index('year')]\n",
    "                    \n",
    "                    # Append extracted data to the list\n",
    "                    data_list.append({\n",
    "                        'song_id': song_id,\n",
    "                        'track_id': track_id,\n",
    "                        'artist_id': artist_id,\n",
    "                        'song_title': song_title,\n",
    "                        'artist_name': artist_name,\n",
    "                        'release': release,\n",
    "                        'artist_terms': artist_terms,\n",
    "                        'artist_terms_freq': artist_terms_freq,\n",
    "                        'song_hotness': hotness,\n",
    "                        'tempo': tempo,\n",
    "                        'loudness': loudness,\n",
    "                        'duration': duration,\n",
    "                        'danceability': danceability,\n",
    "                        'energy': energy,\n",
    "                        'key': key,\n",
    "                        'mode': mode,\n",
    "                        'year': year\n",
    "                    })\n",
    "                    \n",
    "                except KeyError as e:\n",
    "                    print(f\"Missing key {e} in file {file_path}\")\n",
    "\n",
    "df_songs = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = pd.read_csv('data/user_data.txt', sep='\\t', header=None, names=['user_id', 'song_id', 'play_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genres_first = pd.read_csv('data/genre_first.cls', delimiter='\\t', header=None, names=['track_id', 'genre'])\n",
    "df_genres_second = pd.read_csv('data/genre_second.cls', delimiter='\\t', comment='#', header=None, names=['track_id', 'genre'])\n",
    "df_genres_third = pd.read_csv('data/genre_third.cls', delimiter='\\t', comment='#', header=None, names=['track_id', 'genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genres = pd.concat([df_genres_first, df_genres_second, df_genres_third]).drop_duplicates(subset=['track_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_songs_genre = pd.merge(df_songs, df_genres, on='track_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4853"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_songs_genre['genre'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_users, df_songs_genre, on='song_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'song_id', 'play_count', 'track_id', 'artist_id',\n",
       "       'song_title', 'artist_name', 'release', 'artist_terms',\n",
       "       'artist_terms_freq', 'song_hotness', 'tempo', 'loudness', 'duration',\n",
       "       'danceability', 'energy', 'key', 'mode', 'year', 'genre'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering of Songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(772661, 20)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>play_count</th>\n",
       "      <th>song_id</th>\n",
       "      <th>artist_id</th>\n",
       "      <th>song_title</th>\n",
       "      <th>artist_name</th>\n",
       "      <th>release</th>\n",
       "      <th>song_hotness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>loudness</th>\n",
       "      <th>duration</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>year</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b80344d063b5ccb3212f76538f3d9e43d87dca9e</td>\n",
       "      <td>1</td>\n",
       "      <td>SOWEZSI12A81C21CE6</td>\n",
       "      <td>AR2UQQ51187B9AC816</td>\n",
       "      <td>Tu Quieres Volver</td>\n",
       "      <td>Gipsy Kings</td>\n",
       "      <td>Greatest Hits</td>\n",
       "      <td>0.778821</td>\n",
       "      <td>165.006</td>\n",
       "      <td>-8.403</td>\n",
       "      <td>194.87302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>833c530ecda3d99deb8395f70400aa3999783d91</td>\n",
       "      <td>2</td>\n",
       "      <td>SOWEZSI12A81C21CE6</td>\n",
       "      <td>AR2UQQ51187B9AC816</td>\n",
       "      <td>Tu Quieres Volver</td>\n",
       "      <td>Gipsy Kings</td>\n",
       "      <td>Greatest Hits</td>\n",
       "      <td>0.778821</td>\n",
       "      <td>165.006</td>\n",
       "      <td>-8.403</td>\n",
       "      <td>194.87302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    user_id  play_count             song_id  \\\n",
       "0  b80344d063b5ccb3212f76538f3d9e43d87dca9e           1  SOWEZSI12A81C21CE6   \n",
       "1  833c530ecda3d99deb8395f70400aa3999783d91           2  SOWEZSI12A81C21CE6   \n",
       "\n",
       "            artist_id         song_title  artist_name        release  \\\n",
       "0  AR2UQQ51187B9AC816  Tu Quieres Volver  Gipsy Kings  Greatest Hits   \n",
       "1  AR2UQQ51187B9AC816  Tu Quieres Volver  Gipsy Kings  Greatest Hits   \n",
       "\n",
       "   song_hotness    tempo  loudness   duration  danceability  energy  key  \\\n",
       "0      0.778821  165.006    -8.403  194.87302           0.0     0.0    5   \n",
       "1      0.778821  165.006    -8.403  194.87302           0.0     0.0    5   \n",
       "\n",
       "   mode  year genre  \n",
       "0     0  1987   NaN  \n",
       "1     0  1987   NaN  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['user_id', 'play_count', 'song_id','artist_id','song_title','artist_name','release','song_hotness',\n",
    "    'tempo','loudness','duration','danceability','energy','key','mode','year','genre']].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id              0\n",
      "song_id              0\n",
      "play_count           0\n",
      "track_id             0\n",
      "artist_id            0\n",
      "song_title           0\n",
      "artist_name          0\n",
      "release              0\n",
      "artist_terms         0\n",
      "artist_terms_freq    0\n",
      "song_hotness         0\n",
      "tempo                0\n",
      "loudness             0\n",
      "duration             0\n",
      "danceability         0\n",
      "energy               0\n",
      "key                  0\n",
      "mode                 0\n",
      "year                 0\n",
      "genre                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical and categorical columns\n",
    "numerical_cols = ['song_hotness']\n",
    "categorical_cols = ['genre']\n",
    "\n",
    "# Fill NaNs in numerical columns with mean\n",
    "for col in numerical_cols:\n",
    "    df[col].fillna(df[col].mean(), inplace=True)\n",
    "\n",
    "# Fill NaNs in categorical columns with mode\n",
    "for col in categorical_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features for clustering\n",
    "features = ['user_id', 'play_count', 'song_id','artist_id','song_title','artist_name','release','song_hotness',\n",
    "    'tempo','loudness','duration','danceability','energy','key','mode','year','genre']\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcss = []\n",
    "\n",
    "# Try clustering with different number of clusters\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=42)\n",
    "    kmeans.fit(df_scaled)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the Elbow Graph\n",
    "plt.plot(range(1, 11), wcss, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KMeans\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(df_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by clusters and compute mean values\n",
    "cluster_analysis = df.groupby('cluster').mean()\n",
    "print(cluster_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(df_scaled)\n",
    "df_pca = pd.DataFrame(data=principalComponents, columns=['PC1', 'PC2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df_pca['PC1'], df_pca['PC2'], c=df['cluster'])\n",
    "plt.title('Clusters Visualization')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Replace 'your_file.h5' with the path to your .h5 file\n",
    "with h5py.File('Data/msd_summary_file.h5', 'r') as f:\n",
    "    # Function to recursively print group and dataset names\n",
    "    def print_structure(name, obj):\n",
    "        print(name)\n",
    "\n",
    "    # Visit all items and print their names\n",
    "    f.visititems(print_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('Data/msd_summary_file.h5', key='analysis/songs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "print(tables)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SGI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
